# -*- coding: utf-8 -*-
"""Step03 “Lucid Sonic Dreams”

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1omSj-oHqZf37M3mpGCjg-SLjatrjpGqa

# A. Set-Up

## A.1. Set-up GPU

Navigate to **Runtime -> Change runtime type** and make sure **Hardware accelerator** is set to GPU.

## A.2. Download Sample Audio Preview Files
"""

from google.colab import drive
drive.mount('/content/drive')

## CHEMICAL LOVE - BASICALLY SATURDAY NIGHT ## 

! gdown --id 1aTWrzCvJyYcQ82PS6av3YJrtsON2_CUK

## PANCAKE FEET - TENNYSSON ## 

! gdown --id 14MqCkuREr1TmuWaxZd8bnuhVlL_vCE9s

## RASPBERRY - SAJE ## 

! gdown --id 1GqRi4VFEbw46e9RRvuGPtNc7TuOKFbjl

## LUCID SONIC DREAMS DEMO TRACK ##

# Main File
! gdown --id 1Vc2yC2F5iO0ScC5F0CzF_YB1YPGI2uUP

# Pulse File 
! gdown --id 1FY5MO6XqVu9abbdNQQY6C99RHxFGm36o

# Class File
! gdown --id 1-qwcs8_Va58YqkHMdXDm9uef-RcH01gh

## SEA OF VOICES - PORTER ROBINSON ##

# Instrumental (Main Audio)
! gdown --id 13-kS5-3Tw2x9kEVfE3ZMkUN955nw73mN

# Original (Output Audio)
! gdown --id 1r0Mo-vtUIf2njqJ0h3hPJuQELcJ8K2Gu

## UNFAITH - EKALI ## 
! gdown --id 1rgwrhtnVwK2Dom9pJ7p2CBF0j7F2vdkM

"""## A.3. Install Lucid Sonic Dreams"""

! pip install lucidsonicdreams

"""# B. Generate Sample Videos

## B.1. Choosing a Style

Styles can be selected using the **style** parameter, which takes in any of the following:

*   A valid default style name provided by the package. Run **show_styles()** to print valid values. *Note: These styles are loaded from [this repository](https://github.com/justinpinkney/awesome-pretrained-stylegan2) by Justin Pinkney.*

*   A path to a .pkl file that contains pre-trained StyleGAN weights

*   A custom function that takes noise_batch and class_batch parameters and outputs a list of Pillow Images (see example in **B.5**)
"""

from lucidsonicdreams import show_styles 

# Show valid default style names. 
show_styles()

"""## B.2. Using Default Settings

This package is set-up so that the only arguments required are the **file path to your audio track** and the **file name of the video output**. This code snippet outputs a 45-second, low-resolution preview of a video using the "modern art" style, and all the other default settings.

The song used here is **Chemical Love by Basically Saturday Night**. You can watch the official music video [here](https://youtu.be/Gi7oQrtyjKI), or listen to them on [Spotify](https://open.spotify.com/artist/46tGdhXAQbTvxVOGgy0Fqu?si=E8mUjbWbR2uiiMR2MUc_4w)!

Click [here](https://youtu.be/oGXfOmqFYTg) to view a full-length sample video without having to run the code.

## B.3. Tuning Parameters - How It Works

There are **over 30 parameters** you can tune, offering tons of flexibility as to how you want your music to be visualized. This may seem like an overwhelming number, but things are easier to digest once you have a basic understanding of how the visualizer works.

### So, how does it work? 

1. First, a batch of input vectors corresponding to output images is initialized. Linear interpolations between these vectors are produced, serving as the "base" vectors.
2. Three components react to the audio: **Pulse**, **Motion**, and **Class**. These modify the "base" vectors accordingly.

  *   **Pulse**, quite literally, refers to how the visuals "pulse" to the beat of the music. It is set to react to the audio's percussive elements by default. 
  *   **Motion** refers to how the visuals are "pushed forward" or "sped up" by the music, and is set to react to the audio's harmonic elements by default. 
  *   Finally, **Class** refers to the labels of objects shown in the generated images (e.g. in the case of the WikiArt style, classes can refer to Van Gogh, Andy Warhol, Da Vinci, etc). This is set to react to the audio's pitch, where each note controls the prominence of a class. *Note:* Among the default styles available, only WikiArt uses classes thus far.
3. Finally, additional effects - such as contrast and flash - are added to the video. These are set to react to the audio's percussive elements by default.

### The Parameters

Now, the parameters can be easily understood by separating them into 7 categories: Initialization, Pulse, Motion, Class, Effects, Video, and Other. 

If this is still overwhelming, it's recommended that you start off by tuning **speed_fpm**, **pulse_react**, **motion_react** and **class_pitch_react**, and build from there. These parameters make the biggest difference.

##### **Initialization**

* **speed_fpm** (*Default: 12*) - FPM stands for "Frames per Minute". This determines how many images are initialized - the more there are, the faster the visuals morph. If **speed_fpm = 0**, then only one image is initialized, and that single image reacts to the audio. In this case, there will be no motion during silent parts of the audio.

##### **Pulse Parameters**

*   **pulse_react** (*Default: 0.5*) - The "strength" of the pulse. It is recommended to keep this between 0 and 2.
*   **pulse_percussive** (*Default: True*) - If True while *pulse_harmonic* is False, pulse reacts to the audio's percussive elements.
*   **pulse_harmonic** (*Default: False*) - If True while *pulse_percussive* is False, pulse reacts to the audio's harmonic elements.

  *Note*: If both parameters are True or both parameters are False, pulse reacts to the "entire" unaltered audio.
*   **pulse_audio** - Path to a separate audio file to be used to control pulse. This is recommended if you have access to an isolated drum/percussion track. If passed, *pulse_percussive* and *pulse_harmonic* are ignored. *Note:* this parameter is passed when defining the LucidSonicDream object.

##### **Motion Parameters**

*   **motion_react** (*0.5*), **motion_percussive** (*False*), **motion_harmonic** (*True*), and **motion_audio** - Simply the "motion" equivalents of the pulse parameters above. 
*   **motion_randomness** (*Default: 0.5*)- Degree of randomness of motion. Higher values will typically prevent the video from cycling through the same visuals repeatedly. Must range from 0 to 1.
*   **truncation** (*Default: 1*) - Controls the variety of visuals generated. Lower values lead to lower variety. *Note*: A very low value will usually lead to "jittery" visuals. Must range from 0 to 1.

##### **Class Parameters** 

*(Note: Most of these parameters were heavily inspired by the [Deep Music Visualizer](https://github.com/msieg/deep-music-visualizer) project by Matt Siegelman)*

*   **classes** - List of at most 12 numerical object labels. If none, 12 labels are selected at random. 
*   **dominant_classes_first** (*Default: False*)- If True, the list passed to "classes" is sorted by prominence in descending order.
*   **class_pitch_react** (*Default: 0.5*)- Class equivalent of pulse_react and motion_react. It is recommended to keep this between 0 and 2.
*   **class_smooth_seconds** (*Default: 1*) - Number of seconds spent smoothly interpolating between each class vector. The higher the value, the less "sudden" the change of class.
*   **class_complexity** (*Default: 1*) - Controls the "complexity" of images generated. Lower values tend to generate more simple and mundane images, while higher values tend to generate more intricate and bizzare objects. It is recommended to keep this between 0 and 1.
*   **class_shuffle_seconds** (*Default: None*) - Controls the timestamps wherein the mapping of label to note is re-shuffled. This is recommended when the audio used has a limited range of pitches, but you wish for more classes to be shown. If the value passed is a number *n*, classes are shuffled every *n* seconds. If the value passed is a list of numbers, these numbers are used as timestamps (in seconds) wherein classes are shuffled.
*   **class_shuffle_strength** (*Default: 0.5*) - Controls how drastically classes are re-shuffled. Only applies when class_shuffle_seconds is passed. It is recommended to keep this between 0 and 1.
*   **class_audio** - Class equivalent of pulse_audio and motion_audio. Passed when defining the LucidSonicDream object. 

##### **Effects Parameters**

*   **contrast_strength** (*Default: 0.5*) - Strength of default contrast effect. It is recommended to keep this between 0 and 1.
*   **contrast_percussive** (*Default: True*) - If true, contrast reacts to the audio's percussive elements. Must range from 0 to 1.
*   **contrast_audio** - Equivalent of previous "audio" arguments. Passed when defining the LucidSonicDream object.  

  *Note*: If none of these arguments are passed, the contrast effect will not be applied. 

*   **flash_strength** (*0.5*), **flash_percussive** (*True*), and **flash_audio** - Equivalent of the previous three parameters, but for the a "flash" effect. It is recommended to keep these between 0 and 1. If none of these arguments are passed, the flash effect will not be applied. 
*   **custom_effects** - List of custom, user-defined effects to apply (See **B.4**)

##### **Video Parameters**

*   **resolution** - Self-explanatory. Low resolutions are recommended for "trial" renders. If none is passed, unaltered high-resolution images will be used.
*   **start** (*Default: 0*) - Starting timestamp in seconds.
*   **duration** - Video duration in seconds. If none is passed, full duration of audio will be used.
*   **output_audio** - Final output audio of the video. Overwrites audio from "song" parameter if provided (See **B.5**)
*   **fps** (*Default: 43*) - Video Frames Per Second. 
*   **save_frames** (*Default: False*) - If true, saved all individual video frames on disk.

##### **Other**

*   **batch_size** (*Default: 1*) - Determines how many vectors are simoultaneously fed to the model. Typically, larger batch sizes will output less clearly-defined images.

#### Example 1 

This is a simple example whose appeal lies mostly in how it utilizes Motion.

The song used here is **Pancake Feet by Tennysson**. As usual, you can watch the official music video [here](https://youtu.be/_ODm4UZGh7g), or listen to them on [Spotify](https://open.spotify.com/artist/3Nb8N20WChM0swo5qWTvm8?si=oUZ2uV7eQH2ieMucvL_vgA)!

Click [here](https://youtu.be/ztWCMm9cExY) to view a full-length sample video without having to run the code.

#### Example 2

This is another simple example that combines subtle Pulse, Motion, Contrast, and Flash reactions to complement the overall trippy style. 

The style weights used here are from a model trained by **Jeremy Torman**. You can check out his artworks on [Twitter](https://twitter.com/tormanjeremy), or see details on his [original Reddit post](https://www.reddit.com/r/deepdream/comments/leqwxs/stylegan2ada_pickle_file_in_comments_with_colab/) if you're interested!

The song, meanwhile, is **Raspberry by Saje**. You can listen to the full track on [YouTube](https://www.youtube.com/watch?v=fOLxvL0_aMU) or [Spotify](https://open.spotify.com/artist/3I2596dGk4K3e4qKjwpzQb?si=TbyjmQuAQRWmrE--lNTRMg). 

Click [here](https://youtu.be/iEFqcMrszH0) to view a full-length sample video without having to run the code.
"""

# Download Style Weights 
! gdown --id 19hNptJSXji_9h7DMJBVlEMe-izWXvkYQ

L = LucidSonicDream(song = 'I Am Anomaly - Elevator Music .mp3',
                    style = 'network-snapshot-000144.pkl')

L.hallucinate(file_name = 'I Am Anomaly - Elevator Music.mp4',
              resolution = 360,
              duration = 60,
              pulse_react = 1.2,
              motion_react = 0.7,
              contrast_strength = 0.5,
              flash_strength = 0.5)

files.download("I Am Anomaly - Elevator Music.mp4")

"""#### Example 3

This is a much more complex example that utilizes multiple audio tracks and more fine-tuned parameters. It takes advantage of isolated audio tracks for cleaner Pulse, Class, and Contrast reactions.

Note: Numerical labels for classes using the WikiArt style can be found [here](https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/WikiArt_Example_Generation_By_Peter_Baylies.ipynb). 

Click [here](https://youtu.be/l-nGC-ve7sI) to view a full-length sample video without having to run the code.
"""